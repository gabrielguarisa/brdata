{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#api-overview","title":"API Overview","text":""},{"location":"#modules","title":"Modules","text":"<ul> <li>No modules</li> </ul>"},{"location":"#classes","title":"Classes","text":"<ul> <li>No classes</li> </ul>"},{"location":"#functions","title":"Functions","text":"<ul> <li>No functions</li> </ul> <p>This file was automatically generated via lazydocs.</p>"},{"location":"core.crawler/","title":"Core.crawler","text":""},{"location":"core.crawler/#module-corecrawler","title":"module <code>core.crawler</code>","text":""},{"location":"core.crawler/#class-crawler","title":"class <code>Crawler</code>","text":"<p>Base class for crawlers. </p> <p>If you want to create a new crawler, you should inherit from this class. It provides some useful methods for crawling. </p> <p>Args:</p> <ul> <li><code>url</code> (str):  Base url for the crawler. </li> </ul> <p></p>"},{"location":"core.crawler/#method-__init__","title":"method <code>__init__</code>","text":"<pre><code>__init__(url: str)\n</code></pre>"},{"location":"core.crawler/#method-get_page","title":"method <code>get_page</code>","text":"<pre><code>get_page(url: str = None, path: str = &lt;class 'str'&gt;, **kwargs) \u2192 str\n</code></pre> <p>Get a page from a given url. This is just a wrapper around <code>get_response</code> method. </p> <p></p>"},{"location":"core.crawler/#method-get_page_soup","title":"method <code>get_page_soup</code>","text":"<pre><code>get_page_soup(\n    url: str = None,\n    enable_cache: bool = True,\n    **kwargs\n) \u2192 BeautifulSoup\n</code></pre> <p>Get a BeautifulSoup object from a given url. This is just a wrapper around <code>get_page</code> method. </p> <p></p>"},{"location":"core.crawler/#method-get_response","title":"method <code>get_response</code>","text":"<pre><code>get_response(url: str = None, path: str = &lt;class 'str'&gt;, **kwargs) \u2192 Response\n</code></pre> <p>Get a response from a given url. </p> <p>Args:</p> <ul> <li><code>url</code> (str, optional):  Url to get response from. Defaults to None. </li> <li><code>path</code> (str, optional):  Path to join with base url. Defaults to str. </li> <li><code>kwargs</code>:  Keyword arguments to pass to <code>requests.get</code>. </li> </ul> <p>Returns:</p> <ul> <li><code>requests.Response</code>:  Response from the given url. </li> </ul> <p></p>"},{"location":"core.crawler/#method-join_url","title":"method <code>join_url</code>","text":"<pre><code>join_url(*args: str) \u2192 str\n</code></pre> <p>Join url parts. </p> <p>Args:</p> <ul> <li><code>*args (str)</code>:  Url parts. </li> </ul> <p>Returns:</p> <ul> <li><code>str</code>:  Joined url. </li> </ul> <p>This file was automatically generated via lazydocs.</p>"},{"location":"core.exceptions/","title":"Core.exceptions","text":""},{"location":"core.exceptions/#module-coreexceptions","title":"module <code>core.exceptions</code>","text":""},{"location":"core.exceptions/#class-baseexception","title":"class <code>BaseException</code>","text":"<p>Base exception for all brdata exceptions. </p> <p></p>"},{"location":"core.exceptions/#class-requestexception","title":"class <code>RequestException</code>","text":"<p>Exception raised when the maximum number of retries is reached. </p> <p></p>"},{"location":"core.exceptions/#method-__init__","title":"method <code>__init__</code>","text":"<pre><code>__init__(message: str = 'Maximum number of retries reached.', *args, **kwargs)\n</code></pre>"},{"location":"core.exceptions/#class-notfoundexception","title":"class <code>NotFoundException</code>","text":"<p>Exception raised when some resource is not founds. </p> <p>This file was automatically generated via lazydocs.</p>"},{"location":"core/","title":"Core","text":""},{"location":"core/#module-core","title":"module <code>core</code>","text":"<p>This file was automatically generated via lazydocs.</p>"},{"location":"core.req/","title":"Core.req","text":""},{"location":"core.req/#module-corereq","title":"module <code>core.req</code>","text":""},{"location":"core.req/#function-new_user_agent","title":"function <code>new_user_agent</code>","text":"<pre><code>new_user_agent() \u2192 str\n</code></pre> <p>Returns a new random user agent. </p> <p></p>"},{"location":"core.req/#function-get_response_cached","title":"function <code>get_response_cached</code>","text":"<pre><code>get_response_cached(\n    url: str,\n    max_retries: int = 5,\n    timeout: int = 10,\n    verify: bool = True\n) \u2192 Response\n</code></pre> <p>Returns a response from a given url. </p> <p>Args:</p> <ul> <li><code>url</code> (str):  url to get response from. </li> <li><code>max_retries</code> (int, optional):  Maximum number of retries. Defaults to 5. </li> <li><code>timeout</code> (int, optional):  Timeout in seconds. Defaults to 10. </li> <li><code>verify</code> (bool, optional):  Whether to verify SSL certificate. Defaults to True. </li> <li><code>enable_cache</code> (bool, optional):  Whether to use cache or not. Defaults to True. </li> </ul> <p>This file was automatically generated via lazydocs.</p>"},{"location":"crawlers.cvm/","title":"Crawlers.cvm","text":""},{"location":"crawlers.cvm/#module-crawlerscvm","title":"module <code>crawlers.cvm</code>","text":""},{"location":"crawlers.cvm/#global-variables","title":"Global Variables","text":"<ul> <li>VALID_PREFIXES</li> </ul>"},{"location":"crawlers.cvm/#class-cvmcrawler","title":"class <code>CVMCrawler</code>","text":"<p>Crawler for CVM data. </p> <p>Example:</p> <pre><code>import brdata\ncrawler = brdata.CVMCrawler()\ncrawler.get_documents(\"DFP\", 2018, 2020)\n</code></pre> <p></p>"},{"location":"crawlers.cvm/#method-__init__","title":"method <code>__init__</code>","text":"<pre><code>__init__()\n</code></pre>"},{"location":"crawlers.cvm/#method-get_documents","title":"method <code>get_documents</code>","text":"<pre><code>get_documents(\n    prefix: str,\n    start_year: str,\n    end_year: str,\n    enable_cache: bool = True\n)\n</code></pre> <p>Get all documents for a given period. </p> <p>Args:</p> <ul> <li><code>prefix</code> (str):  One of the valid prefixes. See <code>VALID_PREFIXES</code>. </li> <li><code>start_year</code> (str):  Year to start getting documents from. </li> <li><code>end_year</code> (str):  Year to end getting documents from. </li> <li><code>enable_cache</code> (bool, optional):  Whether to use cache or not. Defaults to True. </li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>:  If prefix is not valid. </li> <li><code>ValueError</code>:  If start_year is not valid. </li> <li><code>ValueError</code>:  If end_year is not valid. </li> </ul> <p>Returns:</p> <ul> <li><code>dict</code>:  Dictionary of pandas.DataFrame with the documents. </li> </ul> <p></p>"},{"location":"crawlers.cvm/#method-get_documents_by_year","title":"method <code>get_documents_by_year</code>","text":"<pre><code>get_documents_by_year(prefix: str, year: str, enable_cache: bool = True)\n</code></pre> <p>Get all documents for a given year. </p> <p>Args:</p> <ul> <li><code>prefix</code> (str):  One of the valid prefixes. See <code>VALID_PREFIXES</code>. </li> <li><code>year</code> (str):  Year to get documents from. </li> <li><code>enable_cache</code> (bool, optional):  Whether to use cache or not. Defaults to True. </li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>:  If prefix is not valid. </li> <li><code>ValueError</code>:  If year is not valid. </li> </ul> <p>Returns:</p> <ul> <li><code>dict</code>:  Dictionary of pandas.DataFrame with the documents. </li> </ul> <p>This file was automatically generated via lazydocs.</p>"},{"location":"crawlers/","title":"Crawlers","text":""},{"location":"crawlers/#module-crawlers","title":"module <code>crawlers</code>","text":"<p>This file was automatically generated via lazydocs.</p>"},{"location":"crawlers.valor/","title":"Crawlers.valor","text":""},{"location":"crawlers.valor/#module-crawlersvalor","title":"module <code>crawlers.valor</code>","text":""},{"location":"crawlers.valor/#class-valoreconomicocrawler","title":"class <code>ValorEconomicoCrawler</code>","text":"<p>Crawler for Valor Economico. </p> <p>Examples:</p> <pre><code>import brdata\ncrawler = brdata.ValorEconomicoCrawler()\ncrawler.get_recommended_wallet_by_month(1, 2022)\n</code></pre> <p></p>"},{"location":"crawlers.valor/#method-__init__","title":"method <code>__init__</code>","text":"<pre><code>__init__()\n</code></pre>"},{"location":"crawlers.valor/#method-get_page_soup","title":"method <code>get_page_soup</code>","text":"<pre><code>get_page_soup(\n    month: int,\n    year: int,\n    enable_cache: bool = True,\n    **kwargs\n) \u2192 BeautifulSoup\n</code></pre>"},{"location":"crawlers.valor/#method-get_recommended_wallet","title":"method <code>get_recommended_wallet</code>","text":"<pre><code>get_recommended_wallet(\n    start_date: str,\n    end_date: str,\n    to_pandas: bool = True,\n    enable_cache: bool = True\n)\n</code></pre> <p>Get recommended wallet. </p> <p>Args:</p> <ul> <li><code>start_date</code> (str):  Start date in ISO8601 format. </li> <li><code>end_date</code> (str):  End date in ISO8601 format. </li> <li><code>to_pandas</code> (bool, optional):  If True, returns a pandas.DataFrame. Otherwise, returns a list of dicts. Defaults to True. </li> <li><code>enable_cache</code> (bool, optional):  If True, enables cache. Defaults to True. </li> </ul> <p>Returns:</p> <ul> <li><code>pd.DataFrame</code>:  History of recommended wallet. </li> </ul> <p></p>"},{"location":"crawlers.valor/#method-get_recommended_wallet_by_month","title":"method <code>get_recommended_wallet_by_month</code>","text":"<pre><code>get_recommended_wallet_by_month(\n    month: int,\n    year: int,\n    to_pandas: bool = True,\n    enable_cache: bool = True\n) \u2192 DataFrame\n</code></pre> <p>Get recommended wallet for a given month and year. </p> <p>Args:</p> <ul> <li><code>month</code> (int):  Month. </li> <li><code>year</code> (int):  Year. </li> <li><code>to_pandas</code> (bool, optional):  If True, returns a pandas.DataFrame. Otherwise, returns a list of dicts. Defaults to True. </li> <li><code>enable_cache</code> (bool, optional):  If True, enables cache. Defaults to True. </li> </ul> <p>Returns:</p> <ul> <li><code>pd.DataFrame</code>:  Recommended wallet for a given month and year. </li> </ul> <p></p>"},{"location":"crawlers.valor/#method-get_wallets_from_institutions","title":"method <code>get_wallets_from_institutions</code>","text":"<pre><code>get_wallets_from_institutions(\n    start_date: str,\n    end_date: str,\n    to_pandas: bool = True,\n    enable_cache: bool = True\n)\n</code></pre> <p>Get wallets from institutions. </p> <p>Args:</p> <ul> <li><code>start_date</code> (str):  Start date in ISO8601 format. </li> <li><code>end_date</code> (str):  End date in ISO8601 format. </li> <li><code>to_pandas</code> (bool, optional):  If True, returns a pandas.DataFrame. Otherwise, returns a list of dicts. Defaults to True. </li> <li><code>enable_cache</code> (bool, optional):  If True, enables cache. Defaults to True. </li> </ul> <p>Returns:</p> <ul> <li><code>pd.DataFrame</code>:  History of wallets from institutions. </li> </ul> <p></p>"},{"location":"crawlers.valor/#method-get_wallets_from_institutions_by_month","title":"method <code>get_wallets_from_institutions_by_month</code>","text":"<pre><code>get_wallets_from_institutions_by_month(\n    month: int,\n    year: int,\n    to_pandas: bool = True,\n    enable_cache: bool = True\n) \u2192 DataFrame\n</code></pre> <p>Get wallets from institutions for a given month and year. </p> <p>Args:</p> <ul> <li><code>month</code> (int):  Month. </li> <li><code>year</code> (int):  Year. </li> <li><code>to_pandas</code> (bool, optional):  If True, returns a pandas.DataFrame. Otherwise, returns a list of dicts. Defaults to True. </li> <li><code>enable_cache</code> (bool, optional):  If True, enables cache. Defaults to True. </li> </ul> <p>Returns:</p> <ul> <li><code>pd.DataFrame</code>:  Wallets from institutions for a given month and year. </li> </ul> <p>This file was automatically generated via lazydocs.</p>"},{"location":"crawlers.xpi/","title":"Crawlers.xpi","text":""},{"location":"crawlers.xpi/#module-crawlersxpi","title":"module <code>crawlers.xpi</code>","text":""},{"location":"crawlers.xpi/#class-xpicrawler","title":"class <code>XPICrawler</code>","text":"<p>Crawler for XP Investimentos. </p> <p>Examples:</p> <pre><code>import brdata\ncrawler = brdata.XPICrawler()\ncrawler.get_analysis(\"PETR4\")\n</code></pre> <p></p>"},{"location":"crawlers.xpi/#method-__init__","title":"method <code>__init__</code>","text":"<pre><code>__init__()\n</code></pre>"},{"location":"crawlers.xpi/#method-get_analysis","title":"method <code>get_analysis</code>","text":"<pre><code>get_analysis(\n    code: str,\n    to_pandas: bool = True,\n    enable_cache: bool = True,\n    **kwargs\n) \u2192 Series\n</code></pre> <p>Get stock analysis from XP Investimentos. </p> <p>Args:</p> <ul> <li><code>code</code> (str):  Stock code. </li> <li><code>to_pandas</code> (bool, optional):  Whether to return a pandas.Series or a dict. Defaults to True. </li> <li><code>enable_cache</code> (bool, optional):  Whether to enable cache. Defaults to True. </li> </ul> <p>Raises:</p> <ul> <li><code>exceptions.NotFoundException</code>:  Stock not found. </li> </ul> <p>Returns:</p> <ul> <li><code>pd.Series</code>:  Stock analysis. </li> </ul> <p>This file was automatically generated via lazydocs.</p>"}]}